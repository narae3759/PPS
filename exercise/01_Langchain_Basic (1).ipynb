{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env load \n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\"\n",
    "\n",
    "# check API KEY \n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"API KEY 정보가 없습니다. 확인 후 환경변수에 등록해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Langchain 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Langchain 없이 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저도 때때로 우울할 때 먹는 것으로 위로를 받는 법을 알아요. 빵을 사서 조금이라도 기분이 나아졌으면 좋겠어요. 하지만 더 좋은 방법으로 우울함을 극복하는 방법도 찾아보는 것을 권장해요. 함께 하면 더 좋은 방법을 찾을 수 있을 거예요. 함께 화이팅해요!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 USER의 말에 공감해주는 상답사입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": \"우울해서 빵을 샀어\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Langchain 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x00000147FF5671C0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000147FF5782E0> openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "# Model의 구조\n",
    "from langchain_openai import ChatOpenAI \n",
    "model = ChatOpenAI(model_name = \"gpt-3.5-turbo\") \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 단순 질의응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빵을 산 것이 우울함을 달래줄 수 있기를 바랍니다. 그 빵을 맛있게 먹으면서 기분이 조금이라도 나아지길 기대해봐도 좋을 것 같아요. 그리고 우울한 마음을 털어놓고 이야기할 수 있는 친구나 가족과 소통하는 것도 도움이 될 수 있을 거예요. 힘내세요! 함께 응원해요.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "model = ChatOpenAI(model_name = \"gpt-3.5-turbo\") \n",
    "response = model.invoke(\"오늘 너무 우울해서 빵을 샀어\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 역할 구분 질의응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='우울할 때 당황스럽고 위압감을 느낄 수 있지만, 먹는 것으로 감정을 달래는 것은 일시적인 해결책이 될 수 있습니다. 좀 더 건강한 방법으로 우울함을 극복할 수 있는 방법을 찾아보는 것이 중요합니다. 운동을 하거나 취미 활동을 즐기는 것도 좋은 방법일 수 있습니다. 또한, 친구나 가족과 소통하거나 전문가의 도움을 받는 것도 고려해보세요. 심리적인 안정을 찾는 것이 중요합니다. 함께 이야기를 나누는 것이 도움이 되길 바랍니다.', response_metadata={'token_usage': {'completion_tokens': 222, 'prompt_tokens': 46, 'total_tokens': 268}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c152843a-fa60-4f5e-a3d2-b239777dbacc-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage \n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content = \"당신은 매우 이성적인 사람입니다.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content = \"오늘 너무 우울해서 빵을 샀어\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Langchain + Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def make_chain(prompt):\n",
    "    model = ChatOpenAI(model_name = \"gpt-3.5-turbo\") \n",
    "    chain = LLMChain(prompt=prompt, llm=model)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['object'] template='{object}가 영어로 뭐야?'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{object}가 영어로 뭐야?\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': '다람쥐', 'text': 'squirrel'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = make_chain(prompt)\n",
    "\n",
    "response = chain.invoke({\"object\":\"다람쥐\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language', 'object'] template='{object}가 {language}로 뭐야?'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{object}가 {language}로 뭐야?\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': '다람쥐', 'language': '영어', 'text': 'squirrel'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = make_chain(prompt)\n",
    "\n",
    "response = chain.invoke({\"object\":\"다람쥐\", \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['object'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='영어로 번역해주세요')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['object'], template='{object}'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"영어로 번역해주세요\"),\n",
    "        (\"human\", \"{object}\"),\n",
    "    ]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': '다람쥐', 'text': 'Squirrel'}\n"
     ]
    }
   ],
   "source": [
    "chain = make_chain(prompt)\n",
    "\n",
    "response = chain.invoke({\"object\":\"다람쥐\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language', 'object'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='{language}로 번역해주세요')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['object'], template='{object}'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"{language}로 번역해주세요\"),\n",
    "        (\"human\", \"{object}\"),\n",
    "    ]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': '다람쥐', 'language': '영어', 'text': 'squirrel'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = make_chain(prompt)\n",
    "\n",
    "response = chain.invoke({\"object\":\"다람쥐\", \"language\":\"영어\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 반복 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [{\"object\":\"선풍기\"},{\"object\":\"지하철\"},{\"object\":\"번역\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate.from_template(\"{object} 가 영어로 뭐야?\")\n",
    "prompt2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"영어로 번역해주세요\"),\n",
    "        (\"human\", \"{object}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 1 - apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '선풍기는 영어로 \"fan\" 입니다.'},\n",
       " {'text': 'Subway'},\n",
       " {'text': '번역은 \"translation\" 입니다.'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt 1\n",
    "chain = make_chain(prompt1)\n",
    "\n",
    "response = chain.apply(input_list)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'fan'}, {'text': 'subway'}, {'text': 'Translation'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt 2\n",
    "chain = make_chain(prompt2)\n",
    "\n",
    "response = chain.apply(input_list)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 2 - generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['선풍기는 영어로 \"fan\" 입니다.', 'Subway', '번역은 영어로 translation이라고 합니다.']\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "chain = make_chain(prompt1)\n",
    "\n",
    "response = chain.generate(input_list)\n",
    "print([x[0].text for x in response.generations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fan', 'Subway', 'Translation']\n"
     ]
    }
   ],
   "source": [
    "# Prompt 2\n",
    "chain = make_chain(prompt2)\n",
    "\n",
    "response = chain.generate(input_list)\n",
    "print([x[0].text for x in response.generations])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
